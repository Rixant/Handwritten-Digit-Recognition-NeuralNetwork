{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import relevent libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "print(\"Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load train and test datasets\n",
    "train=pd.read_csv('datasets/train.csv')\n",
    "df=pd.DataFrame(train)  \n",
    "df.head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters and hyper-parameters defined\n",
    "m=100 #number of training examples\n",
    "print(\"No. of examples : {} \".format(m))\n",
    "num_layer = 3 # number of layers\n",
    "input_nodes = train.shape[1]-1# number of input nodes, excludes first column \n",
    "print(\"Input nodes : {} \".format(input_nodes))\n",
    "h1 = 128      # hidden layer 1\n",
    "h2 = 64       # hidden layer 2\n",
    "output_nodes = 10 # number of output nodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize inputs\n",
    "input=((np.asfarray(train.iloc[0:100,1:])).reshape(100,784)/ 255.0 * 0.99) + 0.01 \n",
    "\n",
    "#change output to categorial output \n",
    "output = np.zeros((m, 10))+ 0.01\n",
    "for i in range(m):\n",
    "    output[i, np.array(train.label)[i]] = 0.99\n",
    "    \n",
    "# convert output to float datatype\n",
    "output = output.astype(float)\n",
    "\n",
    "#transpose output and input\n",
    "output=np.transpose(output)\n",
    "input=np.transpose(input)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The size of input is {}.\".format(input_nodes))\n",
    "print(\"The size of output is {}.\".format(output_nodes))\n",
    "print(input.shape)\n",
    "print(input)\n",
    "print(\"output\")\n",
    "print(output.shape)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define sigmoid function\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize the required parameters with array of appropriate dimensions\n",
    "def parameters_initialization(input_nodes, h1, h2, output_nodes):\n",
    "    \n",
    "    #weights are initialized in each layer with random values\n",
    "    W1=np.random.randn(h1,input_nodes)*0.1\n",
    "    b1=np.zeros((h1,1))\n",
    "    W2=np.random.randn(h2, h1)*np.sqrt(1./h2)\n",
    "    b2=np.zeros((h2,1))\n",
    "    W3=np.random.randn(output_nodes, h2)*0.01\n",
    "    b3=np.zeros((output_nodes,1))\n",
    "    \n",
    "    \n",
    "    parameters={\n",
    "        \"W1\":W1,\n",
    "        \"W2\":W2,\n",
    "        \"W3\":W3,\n",
    "        \"b1\":b1,\n",
    "        \"b2\":b2,\n",
    "        \"b3\":b3\n",
    "    }\n",
    "    \n",
    "    return parameters\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters=parameters_initialization(input_nodes, h1, h2, output_nodes)\n",
    "print(parameters['W1'])\n",
    "print(parameters[\"W2\"])\n",
    "print(parameters[\"W3\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#forward propagation\n",
    "def forward_propagation(input,parameters):\n",
    "    \n",
    "    #first layer\n",
    "    Z1=np.dot(parameters[\"W1\"],input)+parameters[\"b1\"]\n",
    "    A1=np.tanh(Z1)\n",
    "    \n",
    "    #second layer\n",
    "    Z2=np.dot(parameters[\"W2\"],A1)+parameters[\"b2\"]\n",
    "    A2=np.tanh(Z2)\n",
    "    \n",
    "    #output layer\n",
    "    Z3=np.dot(parameters[\"W3\"],A2)+parameters[\"b3\"]\n",
    "    A3=sigmoid(Z3)\n",
    "    \n",
    "    \n",
    "    cache={\n",
    "        \"A1\": A1,\n",
    "        \"A2\": A2,\n",
    "        \"A3\": A3,\n",
    "        \"Z1\": Z1,\n",
    "        \"Z2\": Z2,\n",
    "        \"Z3\": Z3\n",
    "        \n",
    "    }\n",
    "    \n",
    "\n",
    "    return A3, cache\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A3, cache=forward_propagation(input,parameters)\n",
    "print(cache[\"A3\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute_cost\n",
    "def compute_cost(A2, output, parameters):\n",
    "    logprobs = np.multiply(np.log(A2),output)\n",
    "    cost = -np.sum(logprobs)/output.shape[1]\n",
    "    return cost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#back propagation\n",
    "def back_propagation(input,output,learning_rate,parameters, cache):\n",
    " \n",
    "    dZ3=cache[\"A3\"]-output\n",
    "    dW3=np.dot(dZ3,cache[\"A2\"].T)/784\n",
    "    db3 = np.sum(dZ3, axis=1, keepdims = True)/784\n",
    "   \n",
    "    \n",
    "    dZ2=np.dot(parameters[\"W3\"].T,dZ3)*(1 - np.power(cache[\"A2\"], 2))\n",
    "    dW2=np.dot(dZ2,cache[\"A1\"].T)/784\n",
    "    db2 = np.sum(dZ2, axis=1, keepdims = True)/784\n",
    "    \n",
    "    \n",
    "    dZ1=np.dot(parameters[\"W2\"].T,dZ2)*(1 - np.power(cache[\"A1\"], 2))\n",
    "    dW1=np.dot(dZ1,input.T)\n",
    "    db1 = np.sum(dZ1, axis=1, keepdims = True)/784\n",
    "    \n",
    "    \n",
    "    \n",
    "    grads={\n",
    "        'dW1':dW1,\n",
    "        'dW2':dW2,\n",
    "        'dW3':dW3,\n",
    "        'db1':db1,\n",
    "        'db2':db2,\n",
    "        'db3':db3\n",
    "    }\n",
    "    \n",
    "\n",
    "    return grads\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#update parameters\n",
    "def update_parameters(parameters,grads):\n",
    "    \n",
    "    W1 = parameters[\"W1\"]-learning_rate*grads[\"dW1\"]\n",
    "    b1 = parameters[\"b1\"]-learning_rate*grads[\"db1\"]\n",
    "    W2 = parameters[\"W2\"]-learning_rate*grads[\"dW2\"]\n",
    "    b2 = parameters[\"b2\"]-learning_rate*grads[\"db2\"]\n",
    "    W3 = parameters[\"W3\"]-learning_rate*grads[\"dW3\"]\n",
    "    b3 = parameters[\"b3\"]-learning_rate*grads[\"db3\"]\n",
    "\n",
    "    \n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"W2\": W2,\n",
    "                  \"W3\": W3,\n",
    "                  \"b1\": b1,\n",
    "                  \"b2\": b2,\n",
    "                  \"b3\": b3\n",
    "                }\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train data\n",
    "num_iterations=2500\n",
    "learning_rate=0.1 \n",
    "parameters=parameters_initialization(input_nodes, h1, h2, output_nodes)\n",
    "for epoch in range(0,num_iterations):\n",
    "    print(\"Iteration: \"+ str(epoch+1)+\"/\"+str(num_iterations))   \n",
    "    A3,cache=forward_propagation(input,parameters) #forward propagation\n",
    "    grads=back_propagation(input,output,learning_rate,parameters,cache) #back propagation\n",
    "    parameters=update_parameters(parameters,grads) #update parameters\n",
    "    print(\"A3\")\n",
    "    print(A3.shape)\n",
    "    print(cache[\"A3\"].T)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file = open(\"datasets/test.csv\", 'r')\n",
    "test = test_file.readlines()\n",
    "test_file.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#showing a random value from the dataset\n",
    "import random\n",
    "random_int = random.randint(0,1000)\n",
    "selected_input = test[random_int].split(',')\n",
    "image_array = np.asfarray(selected_input[0:]).reshape((28,28))\n",
    "plt.imshow(image_array, cmap = 'Greys', interpolation=None)\n",
    "print(\"The target value is: \" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict\n",
    "target_input=((np.asfarray(selected_input).reshape(784,1))/ 255.0 * 0.99) + 0.01 \n",
    "A3,cache=forward_propagation(target_input,parameters)\n",
    "label = np.argmax(A3)   \n",
    "print(\"The predicted number is \" + str(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
